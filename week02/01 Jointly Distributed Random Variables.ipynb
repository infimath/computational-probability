{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the most basic level, inference refers to using an observation to reason about some unknown quantity. In this course, the observation and the unknown quantity are represented by random variables. The main modeling question is: How do these random variables relate?\n",
    "\n",
    "Let's build on our earlier weather example, where now another outcome of interest appears, the temperature, which we quantize into to possible values “hot\" and “cold\". Let's suppose that we have the following probability space:\n",
    "\n",
    "<img src=\"../images/images_sec-joint-rv-prob-space.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "You can check that the nonnegative entries do add to $1$. If we let random variable $W$ be the weather (sunny, rainy, snowy) and random variable $T$ be the temperature (hot, cold), then notice that we could rearrange the table in the following fashion:\n",
    "\n",
    "<img src=\"../images/images_sec-joint-rv-rearrange-table.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "When we talk about two separate random variables, we could view them either as a single “super\" random variable that happens to consist of a pair of values (the first table; notice the label for each outcome corresponds to a pair of values), or we can view the two separate variables along their own different axes (the second table).\n",
    "\n",
    "The first table tells us what the underlying probability space is, which includes what the sample space is (just read off the outcome names) and what the probability is for each of the possible outcomes for the underlying experiment at hand.\n",
    "\n",
    "The second table is called a joint probability table $p_{W,T}$ for random variables $W$ and $T$, and we say that random variables $W$ and $T$ are jointly distributed with the above distribution. Since this table is a rearrangement of the earlier table, it also consists of nonnegative entries that add to $1$.\n",
    "\n",
    "The joint probability table gives probabilities in which $W$ and $T$ co-occur with specific values. For example, in the above, the event that “$W=\\text{sunny}$\" and the event that “$T=\\text{hot}$\" co-occur with probability $3/10$. Notationally, we write\n",
    "\n",
    "$$p_{W,T}(\\text {sunny},\\text {hot})=\\mathbb {P}(W=\\text {sunny},T=\\text {hot})=\\frac{3}{10}.$$\n",
    " \n",
    "**Conceptual note:** Given the joint probability table, we can easily go backwards and write out the first table above, which is the underlying probability space.\n",
    "\n",
    "**Preview of inference:** Inference is all about answering questions like “if we observe that the weather is rainy, what is the probability that the temperature is cold?\" Let's take a look at how one might answer this question.\n",
    "\n",
    "First, if we observe that it is rainy, then we know that “sunny\" and “snowy\" didn't happen so those rows aren't relevant anymore. So the space of possible realizations of the world has shrunk to two options now: $(W=\\text {rainy},T=\\text {hot})$ or $(W=\\text {rainy},T=\\text {cold})$. But what about the probabilities of these two realizations? It's not just $1/30$ and $2/15$ since these don't sum to $1$ — by observing things, adjustments can be made to the probabilities of different realizations but they should still form a valid probability space.\n",
    "\n",
    "Why not just scale both $1/30$ and $2/15$ by the same constant so that they sum to $1$? This can be done by dividing 1/30 and 2/15 by their sum:\n",
    "\n",
    "$$\\text {hot:}\\quad \\frac{\\frac{1}{30}}{\\frac{1}{30}+\\frac{2}{15}}=\\frac{1}{5},\\qquad \\text {cold}:\\quad \\frac{\\frac{2}{15}}{\\frac{1}{30}+\\frac{2}{15}}=\\frac{4}{5}.$$\n",
    " \n",
    "Now they sum to 1. It turns out that, given that we'ved observed the weather to be rainy, these are the correct probabilities for the two options “hot\" and “cold\". Let's formalize the steps. We work backwards, first explaining what the the denominator “$130+215=16$\" above comes from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representing a Joint Probability Table in Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../comp_prob_inference')\n",
    "from comp_prob_inference import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 1: Use dictionaries within a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prob_W_T = {\n",
    "    'sunny' : {'hot': 3/10, 'cold': 1/5 },\n",
    "    'rainy' : {'hot': 1/30, 'cold': 2/15},\n",
    "    'snowy' : {'hot': 0   , 'cold': 1/3 }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           cold       hot\n",
      "rainy  0.133333  0.033333\n",
      "snowy  0.333333  0.000000\n",
      "sunny  0.200000  0.300000\n"
     ]
    }
   ],
   "source": [
    "print_joint_prob_table_dict(prob_W_T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want the probability of $P(W=\\text{rainy} \\textrm{ and }T=\\text{cold})$, we write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13333333333333333"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_W_T['rainy']['cold']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** The problem with this representation is that, we can easily retrive a row but getting a column is ussually hard. But if the distribution is sparse(most entries are zero) then writing in dictiaonay will save a lot of space. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 2: Use a 2D array.\n",
    "\n",
    "Another approach is to directly store the joint probability table as a 2D array, separately keeping track of what the rows and columns are. We use a NumPy array (but really you could use Python lists within a Python list, much like how the previous approach used dictionaries within a dictionary; the indexing syntax changes only slightly):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            hot      cold\n",
      "sunny  0.300000  0.200000\n",
      "rainy  0.033333  0.133333\n",
      "snowy  0.000000  0.333333\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "prob_W_T_rows = ['sunny', 'rainy', 'snowy']\n",
    "prob_W_T_cols = ['hot', 'cold']\n",
    "prob_W_T_array = np.array([[3/10, 1/5], [1/30, 2/15], [0, 1/3]])\n",
    "print_joint_prob_table_array(prob_W_T_array, prob_W_T_rows, prob_W_T_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want the probability of $P(W=\\text{rainy} \\textrm{ and }T=\\text{cold})$, we write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13333333333333333"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_W_T_array[prob_W_T_rows.index('rainy'), prob_W_T_cols.index('cold')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
